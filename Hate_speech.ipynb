{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "id": "P86tNTvWO2X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorboard as tf\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "YQMNDnixPUgJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_dt = pd.read_csv('annotated_dataset.csv', index_col=0)\n",
        "\n",
        "# remove empty strings\n",
        "to_rm = ann_dt[ann_dt['tweet'].str.isspace()].index.to_list()\n",
        "ann_dt = ann_dt.drop(index=to_rm)\n",
        "\n",
        "ann_dt.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "OUIKXOFrQk94",
        "outputId": "01990340-987f-4fbf-f19c-a592ce9ba810"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   tweet     category\n",
              "id                                                                   \n",
              "6429    Come ho sempre detto, destra sinistra la cosa...  Non-Hateful\n",
              "14736                                              Bravo  Non-Hateful\n",
              "17964                                           Ipocrita  Non-Hateful\n",
              "18948                    ma vaffunculo  stronzo di merda      Hateful\n",
              "303     E dire che basterebbe semplicemente votare PD...  Non-Hateful\n",
              "311                              Cos'è : Ursula Dessert?  Non-Hateful\n",
              "31829                                 Che hai detto?????  Non-Hateful\n",
              "34841                                        Addirittura  Non-Hateful\n",
              "325     A parte tutte le polemiche,sarebbe sufficient...  Non-Hateful\n",
              "363                                Sì...con i tuoi amici  Non-Hateful"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f744c977-0f31-4786-9e30-e4ef607e853c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6429</th>\n",
              "      <td>Come ho sempre detto, destra sinistra la cosa...</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14736</th>\n",
              "      <td>Bravo</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17964</th>\n",
              "      <td>Ipocrita</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18948</th>\n",
              "      <td>ma vaffunculo  stronzo di merda</td>\n",
              "      <td>Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>E dire che basterebbe semplicemente votare PD...</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>Cos'è : Ursula Dessert?</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31829</th>\n",
              "      <td>Che hai detto?????</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34841</th>\n",
              "      <td>Addirittura</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>A parte tutte le polemiche,sarebbe sufficient...</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>Sì...con i tuoi amici</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f744c977-0f31-4786-9e30-e4ef607e853c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f744c977-0f31-4786-9e30-e4ef607e853c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f744c977-0f31-4786-9e30-e4ef607e853c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the policycorpus data (Duzha et al, 2021)\n",
        "pctest = pd.read_csv('policycorpus-test.csv', index_col=0)\n",
        "pctrain = pd.read_csv('policycorpus-training.csv', index_col=0)"
      ],
      "metadata": {
        "id": "snYYuHIhbDMy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine my annotated dataset + policycorpus dataset\n",
        "pc = pd.concat([pctest, pctrain])\n",
        "pc['class'] = np.where(pc['class'] == 'n', 'Non-Hateful', 'Hateful')\n",
        "pc = pc.rename(columns={'text':'tweet', 'class':'category'})\n",
        "pc_ann_dt = pd.concat([pc, ann_dt])\n",
        "pc_ann_dt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "BARrCnaZlTDl",
        "outputId": "05db381f-e6fa-4072-ea1d-d79591851c64"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   tweet     category\n",
              "id                                                                   \n",
              "1001   Poi vi scandalizzate se vi paragonano ai nazif...  Non-Hateful\n",
              "1002   Porto il numero tre sulla maglia. Il numero tr...  Non-Hateful\n",
              "1003   Possiamo archiviare per un po qs #esaltata che...  Non-Hateful\n",
              "1004   Possiamo dirlo che la #legge sul divieto per #...  Non-Hateful\n",
              "1005   Possibile non si possa punire pesantemente que...  Non-Hateful\n",
              "...                                                  ...          ...\n",
              "9455                        Vanno condannate simili atti  Non-Hateful\n",
              "15786                                         Cialtrona       Hateful\n",
              "22421                                          Sciacallo      Hateful\n",
              "31039                                        Chi? Lei ?   Non-Hateful\n",
              "34509    Sconvolgente che l'italiano non a capito cos...  Non-Hateful\n",
              "\n",
              "[2419 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcd6d643-cd45-45e8-be3d-912b2f67bb32\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>Poi vi scandalizzate se vi paragonano ai nazif...</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>Porto il numero tre sulla maglia. Il numero tr...</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>Possiamo archiviare per un po qs #esaltata che...</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>Possiamo dirlo che la #legge sul divieto per #...</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>Possibile non si possa punire pesantemente que...</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9455</th>\n",
              "      <td>Vanno condannate simili atti</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15786</th>\n",
              "      <td>Cialtrona</td>\n",
              "      <td>Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22421</th>\n",
              "      <td>Sciacallo</td>\n",
              "      <td>Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31039</th>\n",
              "      <td>Chi? Lei ?</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34509</th>\n",
              "      <td>Sconvolgente che l'italiano non a capito cos...</td>\n",
              "      <td>Non-Hateful</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2419 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcd6d643-cd45-45e8-be3d-912b2f67bb32')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcd6d643-cd45-45e8-be3d-912b2f67bb32 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcd6d643-cd45-45e8-be3d-912b2f67bb32');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filename):\n",
        "    df = pd.read_csv(filename, index_col=0)\n",
        "    return df\n",
        "\n",
        "def preprocess_tweet(tweet):\n",
        "    tweet = str(tweet)\n",
        "    # Remove URLs, RTs, and twitter handles\n",
        "    tweet = re.sub(r'http\\S+', '', tweet)\n",
        "    tweet = re.sub(r'@[A-Za-z0-9]+', '', tweet)\n",
        "    tweet = re.sub(r'@\\w+', '', tweet)\n",
        "    tweet = re.sub(r'RT[\\s]+', '', tweet)\n",
        "    # Remove punctuation\n",
        "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
        "    # Lowercase text\n",
        "    tweet = tweet.lower() \n",
        "    return tweet\n",
        "\n",
        "def build_model(df, model, vectorizer=None):\n",
        "    # Preprocess text data\n",
        "    df[\"tweet\"] = df[\"tweet\"].apply(preprocess_tweet)\n",
        "    \n",
        "    # Split data into training and testing sets\n",
        "    X = df[\"tweet\"]\n",
        "    y = df[\"category\"]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=22)\n",
        "    \n",
        "    if model in [\"naive_bayes\", \"random_forest\", \"xgboost\", \"logistic_regression\"]:\n",
        "        # Vectorize the text data\n",
        "        if vectorizer == \"count\":\n",
        "            vectorizer = CountVectorizer()\n",
        "        elif vectorizer == \"tfidf\":\n",
        "            vectorizer = TfidfVectorizer()\n",
        "        X_train = vectorizer.fit_transform(X_train)\n",
        "        X_test = vectorizer.transform(X_test)\n",
        "        \n",
        "        # Train and evaluate the model\n",
        "        if model == \"naive_bayes\":\n",
        "            clf = MultinomialNB()\n",
        "        elif model == \"random_forest\":\n",
        "            clf = RandomForestClassifier()\n",
        "        elif model == \"xgboost\":\n",
        "            clf = XGBClassifier()\n",
        "            y_train = np.where(y_train == 'Hateful', 1, 0)\n",
        "            y_test = np.where(y_test == 'Hateful', 1, 0)\n",
        "        elif model == \"logistic_regression\":\n",
        "            clf = LogisticRegression()\n",
        "\n",
        "        clf.fit(X_train, y_train)\n",
        "        print(f\"Model: {model}\")\n",
        "        accuracy = clf.score(X_test, y_test)\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        \n",
        "        # Perform cross-validation\n",
        "        scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
        "        print(f\"Cross Validation Score: {scores.mean()}\")\n",
        "        print(\"---------------------------------------\")\n",
        "        return accuracy, scores.mean()\n",
        "    \n",
        "    elif model in ['MilaNLProc/hate-ita', 'MilaNLProc/hate-ita-xlm-r-base', 'MilaNLProc/hate-ita-xlm-r-large']:\n",
        "        classifier = pipeline(\"text-classification\",model=model,top_k=2)\n",
        "\n",
        "        # Get the predictions for the test set\n",
        "        predictions = []\n",
        "        for text in X_test:\n",
        "            prediction = classifier(text)[0][0]['label']\n",
        "            if prediction == 'non-hateful':\n",
        "                prediction = 'Non-Hateful'\n",
        "            else:\n",
        "                prediction = 'Hateful'\n",
        "            predictions.append(prediction)\n",
        "        accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "        print(f\"Model: {model}\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(\"---------------------------------------\")\n",
        "        return accuracy, np.nan\n",
        "\n",
        "results = []\n",
        "models = [\"naive_bayes\", \"random_forest\", \"xgboost\", \"logistic_regression\"]\n",
        "models_2 = ['MilaNLProc/hate-ita', 'MilaNLProc/hate-ita-xlm-r-base', 'MilaNLProc/hate-ita-xlm-r-large']\n",
        "vectorizations = [\"count\", \"tfidf\"]\n",
        "\n",
        "for model in models:\n",
        "    for vec in vectorizations:\n",
        "        accuracy, cv_score = build_model(pc_ann_dt, model, vec)\n",
        "        results.append([model, vec, accuracy, cv_score])\n",
        "\n",
        "for model in models_2:\n",
        "    # no need for vectorization\n",
        "    accuracy, cv_score = build_model(pc_ann_dt, model)\n",
        "    results.append([model, 'NaN', accuracy, cv_score])\n",
        "        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe9vtO1CN__z",
        "outputId": "38f81741-d576-44ba-c76f-ce1044759449"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: naive_bayes\n",
            "Accuracy: 0.8429752066115702\n",
            "Cross Validation Score: 0.7944441535319683\n",
            "---------------------------------------\n",
            "Model: naive_bayes\n",
            "Accuracy: 0.837465564738292\n",
            "Cross Validation Score: 0.8115777347227313\n",
            "---------------------------------------\n",
            "Model: random_forest\n",
            "Accuracy: 0.8443526170798898\n",
            "Cross Validation Score: 0.8174844216369064\n",
            "---------------------------------------\n",
            "Model: random_forest\n",
            "Accuracy: 0.8360881542699724\n",
            "Cross Validation Score: 0.8163027351590999\n",
            "---------------------------------------\n",
            "Model: xgboost\n",
            "Accuracy: 0.8388429752066116\n",
            "Cross Validation Score: 0.8151245396310065\n",
            "---------------------------------------\n",
            "Model: xgboost\n",
            "Accuracy: 0.8388429752066116\n",
            "Cross Validation Score: 0.8163062261088129\n",
            "---------------------------------------\n",
            "Model: logistic_regression\n",
            "Accuracy: 0.8457300275482094\n",
            "Cross Validation Score: 0.8198512855422317\n",
            "---------------------------------------\n",
            "Model: logistic_regression\n",
            "Accuracy: 0.837465564738292\n",
            "Cross Validation Score: 0.8121659597493498\n",
            "---------------------------------------\n",
            "Model: MilaNLProc/hate-ita\n",
            "Accuracy: 0.6818\n",
            "---------------------------------------\n",
            "Model: MilaNLProc/hate-ita-xlm-r-base\n",
            "Accuracy: 0.5937\n",
            "---------------------------------------\n",
            "Model: MilaNLProc/hate-ita-xlm-r-large\n",
            "Accuracy: 0.6915\n",
            "---------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "MAX_LENGTH = 256\n",
        "pc_ann_dt['category_n'] = np.where(pc_ann_dt['category'] == 'Non-Hateful', 0, 1)\n",
        "pc_ann_dt['tweet'] = pc_ann_dt['tweet'].apply(lambda x: preprocess_tweet(x))\n",
        "\n",
        "# Load the annotated dataset\n",
        "texts = pc_ann_dt['tweet'].to_list() # List of texts\n",
        "labels = pc_ann_dt['category_n'].to_list() # List of labels (0 for non-hateful, 1 for hateful)\n",
        "\n",
        "# Load the pre-trained tokenizer\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"MilaNLProc/hate-ita-xlm-r-large\")\n",
        "\n",
        "# Convert texts and labels to input_ids and labels using the tokenizer\n",
        "input_ids = [tokenizer.encode(text, add_special_tokens=True, max_length=MAX_LENGTH) for text in texts]\n",
        "\n",
        "# Pad input_ids so that they have the same length\n",
        "input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids, maxlen=MAX_LENGTH, dtype=\"long\", value=0, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "# Convert labels to numpy array\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=1, test_size=0.30)\n",
        "\n",
        "# Convert inputs and labels to tensors\n",
        "train_inputs = tf.constant(train_inputs, dtype=tf.int32)\n",
        "validation_inputs = tf.constant(validation_inputs, dtype=tf.int32)\n",
        "train_labels = tf.constant(train_labels, dtype=tf.int32)\n",
        "\n",
        "# Load the pre-trained PyTorch model\n",
        "model = transformers.TFBertForSequenceClassification.from_pretrained('MilaNLProc/hate-ita-xlm-r-large', from_pt=True)\n",
        "\n",
        "# Freeze the base model layer (bert)\n",
        "model.bert.trainable = False\n",
        "\n",
        "# Remove the last layer\n",
        "model.classifier = None\n",
        "\n",
        "# Add a new layer for your specific task\n",
        "model.classifier = tf.keras.layers.Dense(units=2, activation='softmax')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create a TensorFlow data adapter\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels)).batch(32)\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_inputs, validation_labels)).batch(32)\n",
        "\n",
        "with tf.device(\"GPU:0\"): # change the GPU index based on your setup\n",
        "    # Train the model using your task-specific data\n",
        "    history = model.fit(train_dataset, epochs=2, validation_data=validation_dataset)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "test_loss, test_accuracy = model.evaluate(validation_dataset)\n",
        "\n",
        "# Print the overall metrics\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqyQ4DatFcDT",
        "outputId": "3b78628b-3273-460a-b6da-c06ca2820075"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "You are using a model of type xlm-roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'classifier.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'classifier.dense.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'classifier.out_proj.weight', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'classifier.out_proj.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.key.bias']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "53/53 [==============================] - 45s 410ms/step - loss: 0.5404 - accuracy: 0.7933 - val_loss: 0.5293 - val_accuracy: 0.8044\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 16s 298ms/step - loss: 0.4867 - accuracy: 0.8234 - val_loss: 0.5414 - val_accuracy: 0.8044\n",
            "23/23 [==============================] - 4s 182ms/step - loss: 0.5414 - accuracy: 0.8044\n",
            "Test Loss: 0.5414384603500366\n",
            "Test Accuracy: 0.8044077157974243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.append(['hate-ita-xlm-r-large-fine-tuned', np.nan, test_accuracy, np.nan])"
      ],
      "metadata": {
        "id": "Sy1Ao1UiQ4If"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(results, columns=[\"model\", \"vectorization\", \"accuracy\", \"cv_score\"])\n",
        "df_results.to_csv(\"results.csv\", index=False)"
      ],
      "metadata": {
        "id": "P8TYMwHPQwUS"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results.sort_values(by='accuracy', ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "Xap5uwgCUu9l",
        "outputId": "c7018315-2b4e-4800-9b1a-2000ec1bd9bd"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              model vectorization  accuracy  cv_score\n",
              "6               logistic_regression         count  0.845730  0.819851\n",
              "2                     random_forest         count  0.844353  0.817484\n",
              "0                       naive_bayes         count  0.842975  0.794444\n",
              "4                           xgboost         count  0.838843  0.815125\n",
              "5                           xgboost         tfidf  0.838843  0.816306\n",
              "1                       naive_bayes         tfidf  0.837466  0.811578\n",
              "7               logistic_regression         tfidf  0.837466  0.812166\n",
              "3                     random_forest         tfidf  0.836088  0.816303\n",
              "11  hate-ita-xlm-r-large-fine-tuned           NaN  0.804408       NaN\n",
              "10  MilaNLProc/hate-ita-xlm-r-large           NaN  0.691460       NaN\n",
              "8               MilaNLProc/hate-ita           NaN  0.681818       NaN\n",
              "9    MilaNLProc/hate-ita-xlm-r-base           NaN  0.593664       NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c755ccec-1251-4b25-88fc-49cf04f47545\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>vectorization</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>cv_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>logistic_regression</td>\n",
              "      <td>count</td>\n",
              "      <td>0.845730</td>\n",
              "      <td>0.819851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>random_forest</td>\n",
              "      <td>count</td>\n",
              "      <td>0.844353</td>\n",
              "      <td>0.817484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>naive_bayes</td>\n",
              "      <td>count</td>\n",
              "      <td>0.842975</td>\n",
              "      <td>0.794444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xgboost</td>\n",
              "      <td>count</td>\n",
              "      <td>0.838843</td>\n",
              "      <td>0.815125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>xgboost</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>0.838843</td>\n",
              "      <td>0.816306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>naive_bayes</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>0.837466</td>\n",
              "      <td>0.811578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>logistic_regression</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>0.837466</td>\n",
              "      <td>0.812166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>random_forest</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>0.836088</td>\n",
              "      <td>0.816303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>hate-ita-xlm-r-large-fine-tuned</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.804408</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>MilaNLProc/hate-ita-xlm-r-large</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.691460</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MilaNLProc/hate-ita</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>MilaNLProc/hate-ita-xlm-r-base</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.593664</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c755ccec-1251-4b25-88fc-49cf04f47545')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c755ccec-1251-4b25-88fc-49cf04f47545 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c755ccec-1251-4b25-88fc-49cf04f47545');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "replies = pd.read_csv('all_replies.csv', index_col=0)"
      ],
      "metadata": {
        "id": "iEYSOdibMakR"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_tweet(tweet):\n",
        "    tweet = str(tweet)\n",
        "    # Remove URLs, RTs, and twitter handles\n",
        "    tweet = re.sub(r'http\\S+', '', tweet)\n",
        "    tweet = re.sub(r'@[A-Za-z0-9]+', '', tweet)\n",
        "    tweet = re.sub(r'@\\w+', '', tweet)\n",
        "    tweet = re.sub(r'RT[\\s]+', '', tweet)\n",
        "    # Remove punctuation\n",
        "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
        "    # Lowercase text\n",
        "    tweet = tweet.lower() \n",
        "    return tweet"
      ],
      "metadata": {
        "id": "nW-_cuBxDoGm"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features (text) and labels (hate speech or not)\n",
        "texts = pc_ann_dt['tweet'].apply(preprocess_tweet)\n",
        "labels = pc_ann_dt['category'].values\n",
        "\n",
        "# Convert text to numerical feature vectors using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Train the Logistic Regression model using cross-validation\n",
        "clf_lr = LogisticRegression()\n",
        "clf_lr.fit(X, labels)\n",
        "\n",
        "# Load the new dataframe with tweets\n",
        "new_df = replies\n",
        "\n",
        "# Step 4: Preprocess the tweets in the new dataframe\n",
        "new_texts = new_df['reply'].apply(preprocess_tweet)\n",
        "\n",
        "# Step 5: Convert the new tweets to numerical feature vectors\n",
        "new_X = vectorizer.transform(new_texts)\n",
        "\n",
        "# Step 6: Make predictions on the new dataframe\n",
        "predictions = clf_lr.predict(new_X)\n",
        "\n"
      ],
      "metadata": {
        "id": "7q04ZqBSVkL1"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replies['hate'] = predictions"
      ],
      "metadata": {
        "id": "YqKycLyFabkR"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replies[replies['hate'] == 'Hateful'].head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "beFOfS6GavjL",
        "outputId": "7fb0cfab-9ff1-4d07-8bc4-84ebc95245c2"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           source_tweet                                              reply  \\\n",
              "0   1610630350279004160    Oggi sei particolarmente scatenato, non ries...   \n",
              "2   1610630350279004160  E adesso aspettiamo con ansia cosa ne pensa Or...   \n",
              "28  1610533803910463488   Ascani ma vaffanculo… ma perché non lo avete ...   \n",
              "45  1610533803910463488  Ascani non dire cazzate come tuo solito       ...   \n",
              "50  1610533803910463488   Ogni giorno appare qualche emerito sconosciut...   \n",
              "\n",
              "       hate  \n",
              "0   Hateful  \n",
              "2   Hateful  \n",
              "28  Hateful  \n",
              "45  Hateful  \n",
              "50  Hateful  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f780c39b-d0b6-4364-8d4f-663804206775\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_tweet</th>\n",
              "      <th>reply</th>\n",
              "      <th>hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1610630350279004160</td>\n",
              "      <td>Oggi sei particolarmente scatenato, non ries...</td>\n",
              "      <td>Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1610630350279004160</td>\n",
              "      <td>E adesso aspettiamo con ansia cosa ne pensa Or...</td>\n",
              "      <td>Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1610533803910463488</td>\n",
              "      <td>Ascani ma vaffanculo… ma perché non lo avete ...</td>\n",
              "      <td>Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1610533803910463488</td>\n",
              "      <td>Ascani non dire cazzate come tuo solito       ...</td>\n",
              "      <td>Hateful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>1610533803910463488</td>\n",
              "      <td>Ogni giorno appare qualche emerito sconosciut...</td>\n",
              "      <td>Hateful</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f780c39b-d0b6-4364-8d4f-663804206775')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f780c39b-d0b6-4364-8d4f-663804206775 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f780c39b-d0b6-4364-8d4f-663804206775');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(replies[replies['hate'] == 'Hateful'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXmLWoFAcgvn",
        "outputId": "5aa89db4-5f8c-4eea-cfdd-ea0c7eaf53b6"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11248"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "replies.to_csv('all_replies_hs.csv', index=False)"
      ],
      "metadata": {
        "id": "dxrbhEEz9klj"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataframe of tweets\n",
        "tweets = pd.read_csv('all_tweets_19L.csv', index_col=0) \n",
        "\n",
        "# Filter the dataframe based on the time column\n",
        "tweets = tweets[tweets[\"Time\"] >= '2023-01-02 00:00:00+00:00']\n",
        "\n",
        "classifier = pipeline(\"text-classification\",model='MilaNLProc/feel-it-italian-sentiment',top_k=3)\n",
        "\n",
        "\n",
        "def get_sentiment(tweet):\n",
        "    if type(tweet) is not str:\n",
        "        return np.nan\n",
        "    prediction = classifier(tweet)[0][0]\n",
        "    return prediction['label']\n",
        "\n",
        "tweets['Tweet'] = tweets['Tweet'].apply(preprocess_tweet)\n",
        "tweets['Sentiment'] = tweets['Tweet'].apply(get_sentiment)"
      ],
      "metadata": {
        "id": "f5-Zk6nscgmi"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets.to_csv('all_tweets_sentiment.csv')"
      ],
      "metadata": {
        "id": "tKbGxX1X694c"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fkRutqcN8RwO",
        "outputId": "c7827c72-925d-4cd7-91cd-db449ca94464"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Tweet_ID                       Time             User  \\\n",
              "0       1614929198455332864  2023-01-16 10:14:59+00:00   DavideAiello85   \n",
              "1594    1619970156603781120  2023-01-30 08:05:57+00:00     amendolaenzo   \n",
              "1595    1619694030069309440  2023-01-29 13:48:43+00:00     amendolaenzo   \n",
              "1596    1619293651200516096  2023-01-28 11:17:46+00:00     amendolaenzo   \n",
              "1597    1618882526122217474  2023-01-27 08:04:06+00:00     amendolaenzo   \n",
              "...                     ...                        ...              ...   \n",
              "200114  1613304423345979392  2023-01-11 22:38:42+00:00  eugenio_zoffili   \n",
              "200115  1611868863779446784  2023-01-07 23:34:18+00:00  eugenio_zoffili   \n",
              "200116  1611868573093474305  2023-01-07 23:33:09+00:00  eugenio_zoffili   \n",
              "200117  1611782683708858372  2023-01-07 17:51:51+00:00  eugenio_zoffili   \n",
              "200118  1610787343048343553  2023-01-04 23:56:44+00:00  eugenio_zoffili   \n",
              "\n",
              "                                                    Tweet Sentiment  \n",
              "0       finalmente dopo 30 anni finisce la latitanza d...  negative  \n",
              "1594    giovanni lettieri sindaco di picerno candidato...  positive  \n",
              "1595    il decretoong è profondamente sbagliato una ma...  negative  \n",
              "1596    gravi gli attacchi alle sedi diplomatiche ital...  negative  \n",
              "1597    nei campi di sterminio rimasi sola e non rivid...  negative  \n",
              "...                                                   ...       ...  \n",
              "200114  con orgoglio e un po di emozione oggi nella se...  positive  \n",
              "200115  qui si sta realizzando unopera che conta più d...  positive  \n",
              "200116  oggi a casalpusterlengo lo nel comune del nost...  positive  \n",
              "200117  vi aspettiamo a como con matteo salvini \\npren...  positive  \n",
              "200118  ci vediamo a casalpusterlengo con il nostro ma...  positive  \n",
              "\n",
              "[3646 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0fee2f1-e16b-40f2-af44-58431d9f6ee2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>Time</th>\n",
              "      <th>User</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1614929198455332864</td>\n",
              "      <td>2023-01-16 10:14:59+00:00</td>\n",
              "      <td>DavideAiello85</td>\n",
              "      <td>finalmente dopo 30 anni finisce la latitanza d...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1594</th>\n",
              "      <td>1619970156603781120</td>\n",
              "      <td>2023-01-30 08:05:57+00:00</td>\n",
              "      <td>amendolaenzo</td>\n",
              "      <td>giovanni lettieri sindaco di picerno candidato...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1595</th>\n",
              "      <td>1619694030069309440</td>\n",
              "      <td>2023-01-29 13:48:43+00:00</td>\n",
              "      <td>amendolaenzo</td>\n",
              "      <td>il decretoong è profondamente sbagliato una ma...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1596</th>\n",
              "      <td>1619293651200516096</td>\n",
              "      <td>2023-01-28 11:17:46+00:00</td>\n",
              "      <td>amendolaenzo</td>\n",
              "      <td>gravi gli attacchi alle sedi diplomatiche ital...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>1618882526122217474</td>\n",
              "      <td>2023-01-27 08:04:06+00:00</td>\n",
              "      <td>amendolaenzo</td>\n",
              "      <td>nei campi di sterminio rimasi sola e non rivid...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200114</th>\n",
              "      <td>1613304423345979392</td>\n",
              "      <td>2023-01-11 22:38:42+00:00</td>\n",
              "      <td>eugenio_zoffili</td>\n",
              "      <td>con orgoglio e un po di emozione oggi nella se...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200115</th>\n",
              "      <td>1611868863779446784</td>\n",
              "      <td>2023-01-07 23:34:18+00:00</td>\n",
              "      <td>eugenio_zoffili</td>\n",
              "      <td>qui si sta realizzando unopera che conta più d...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200116</th>\n",
              "      <td>1611868573093474305</td>\n",
              "      <td>2023-01-07 23:33:09+00:00</td>\n",
              "      <td>eugenio_zoffili</td>\n",
              "      <td>oggi a casalpusterlengo lo nel comune del nost...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200117</th>\n",
              "      <td>1611782683708858372</td>\n",
              "      <td>2023-01-07 17:51:51+00:00</td>\n",
              "      <td>eugenio_zoffili</td>\n",
              "      <td>vi aspettiamo a como con matteo salvini \\npren...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200118</th>\n",
              "      <td>1610787343048343553</td>\n",
              "      <td>2023-01-04 23:56:44+00:00</td>\n",
              "      <td>eugenio_zoffili</td>\n",
              "      <td>ci vediamo a casalpusterlengo con il nostro ma...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3646 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0fee2f1-e16b-40f2-af44-58431d9f6ee2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0fee2f1-e16b-40f2-af44-58431d9f6ee2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0fee2f1-e16b-40f2-af44-58431d9f6ee2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import pipeline\n",
        "from statsmodels.formula.api import ols\n",
        "from scipy import stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
      ],
      "metadata": {
        "id": "cdQ_96C48ILH"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replies = pd.read_csv('all_replies_hs.csv', index_col=0)\n",
        "accounts = pd.read_csv('twitter_veracc.csv', index_col=0)\n",
        "tweets = pd.read_csv('all_tweets_sentiment.csv', index_col=0)"
      ],
      "metadata": {
        "id": "IgufN6drA5CA"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replies = replies.rename(columns={'hate':'Hate_score'})\n",
        "\n",
        "accounts['parliamentary_group'] = accounts['parliamentary_group'].replace({\n",
        "    'Movimento 5 Stelle':'M5S', \n",
        "    'Partito Democratico':'PD',\n",
        "    'Lega':'LEGA',\n",
        "    \"Fratelli d'Italia\":'FDI', \n",
        "    'Azione - Italia Viva':'AzIV'\n",
        "})"
      ],
      "metadata": {
        "id": "3g7xTVYe7c9x"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "sent = pd.merge(accounts, tweets, left_on='screen_name', right_on='User')\n",
        "\n",
        "# Group the dataframe by parliamentary_group and sentiment\n",
        "grouped = sent.groupby([\"parliamentary_group\", \"Sentiment\"]).size().reset_index(name=\"count\")\n",
        "\n",
        "# Pivot the grouped dataframe to create a new dataframe with the sentiment as columns and parliamentary_group as index\n",
        "pivot = grouped.pivot(index=\"parliamentary_group\", columns=\"Sentiment\", values=\"count\")\n",
        "\n",
        "# Fill missing values with 0\n",
        "pivot = pivot.fillna(0)\n",
        "\n",
        "# Calculate the total number of tweets for each parliamentary_group\n",
        "total_tweets = pivot.sum(axis=1)\n",
        "\n",
        "# Calculate the percentage of tweets with each sentiment for each parliamentary_group\n",
        "pivot[\"positive\"] = pivot[\"positive\"] / total_tweets\n",
        "pivot[\"negative\"] = pivot[\"negative\"] / total_tweets\n",
        "\n",
        "# Plot the bar chart\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "pivot.plot.bar(ax=ax, stacked=True, color=[\"lightgreen\", \"lightgrey\", \"red\"], edgecolor=\"black\")\n",
        "ax.set_xlabel(\"Parliamentary Group\")\n",
        "ax.set_ylabel(\"Percentage of Tweets\")\n",
        "ax.set_title(\"Percentage of Positive and Negative Tweets by Parliamentary Group\")\n",
        "ax.legend(title=\"Sentiment\", loc=\"best\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "q4EBPmoW2a-N",
        "outputId": "55fde7e7-e19a-4543-f626-27762386a94c"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pivot.round(4).multiply(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "cXbJNOWi2meW",
        "outputId": "a6f7f364-d799-4f27-fad9-6f8464c3ed83"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment            negative  positive\n",
              "parliamentary_group                    \n",
              "AzIV                    63.56     36.44\n",
              "FDI                     45.43     54.57\n",
              "LEGA                    63.04     36.96\n",
              "M5S                     78.76     21.24\n",
              "PD                      69.68     30.32"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7835174-5b07-4521-8ee1-8f9639fcfab1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Sentiment</th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parliamentary_group</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AzIV</th>\n",
              "      <td>63.56</td>\n",
              "      <td>36.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FDI</th>\n",
              "      <td>45.43</td>\n",
              "      <td>54.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEGA</th>\n",
              "      <td>63.04</td>\n",
              "      <td>36.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M5S</th>\n",
              "      <td>78.76</td>\n",
              "      <td>21.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PD</th>\n",
              "      <td>69.68</td>\n",
              "      <td>30.32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7835174-5b07-4521-8ee1-8f9639fcfab1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7835174-5b07-4521-8ee1-8f9639fcfab1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7835174-5b07-4521-8ee1-8f9639fcfab1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merge the tweets and replies dataframes on 'source_tweet' column\n",
        "merged_df = pd.merge(replies, tweets, left_on='source_tweet', right_on='Tweet_ID')\n",
        "\n",
        "# merge the resulting dataframe with the accounts dataframe on 'User' column\n",
        "final_df = pd.merge(merged_df, accounts, left_on='User', right_on='screen_name')\n",
        "\n",
        "# select columns from final dataframe\n",
        "final_df = final_df[['Tweet_ID', 'Hate_score', 'followers_count', 'gender', 'parliamentary_group', 'Sentiment']]\n",
        "final_df = final_df.dropna()\n",
        "#final_df['Hate_score'] = np.where(final_df['Hate_score'] > 0.5, 1,0)"
      ],
      "metadata": {
        "id": "GfjYwQ80L1yE"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv('final.csv', index=False)"
      ],
      "metadata": {
        "id": "7i0V3QlEUc3O"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data into a pandas dataframe\n",
        "df = final_df\n",
        "#df['Hate_score'] = np.where(df['Hate_score'] > 0.5, 'Hateful', 'Non_Hateful')\n",
        "\n",
        "# Create a contingency table for the relationship between gender and Hate_score\n",
        "gender_Hate_table = pd.crosstab(df[\"gender\"], df[\"Hate_score\"])\n",
        "chi2, p_val, dof, expected = stats.chi2_contingency(gender_Hate_table)\n",
        "print(\"Chi-squared test results for gender and Hate_score: chi2 =\", chi2, \"and p-value =\", p_val)\n",
        "\n",
        "# Create a contingency table for the relationship between parliamentary_group and Hate_score\n",
        "parliamentary_group_Hate_table = pd.crosstab(df[\"parliamentary_group\"], df[\"Hate_score\"])\n",
        "chi2, p_val, dof, expected = stats.chi2_contingency(parliamentary_group_Hate_table)\n",
        "print(\"Chi-squared test results for parliamentary_group and Hate_score: chi2 =\", chi2, \"and p-value =\", p_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUSL-g58y_T",
        "outputId": "d6ae5058-163a-4228-b825-4b61800a0620"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-squared test results for gender and Hate_score: chi2 = 0.18720147505021245 and p-value = 0.6652560839864929\n",
            "Chi-squared test results for parliamentary_group and Hate_score: chi2 = 68.01138627387822 and p-value = 5.965595448529471e-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of the chi-squared test indicate that there is a significant relationship between the \"Hate_score\" variable and the \"parliamentary_group\" variable. (p-values < 0.05). This suggests that the distribution of \"Hateful\" and \"Non-Hateful\" scores is not the same across the different groups defined by \"gender\". \n",
        "\n",
        "The p-value for the relationship between \"parliamentary_group\" and \"Hate_score\" is {p_val}, much smaller than 0.05, so we can reject the null hypothesis that the distribution of \"Hateful\" and \"Non-Hateful\" scores is the same for the different parliamentary groups.\n",
        "\n",
        "There is no significant association between gender and hate speech in replies."
      ],
      "metadata": {
        "id": "CqB_wshY82QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select columns from final dataframe\n",
        "df = final_df[['Tweet_ID', 'Hate_score', 'followers_count', 'gender', 'parliamentary_group']]\n",
        "grouped = df.groupby(\"parliamentary_group\")[\"Hate_score\"].apply(lambda x: (x == \"Hateful\").mean()).reset_index()\n",
        "# Plot the percentage of \"Hateful\" scores for each gender\n",
        "plt.bar(grouped[\"parliamentary_group\"], grouped[\"Hate_score\"])\n",
        "plt.xlabel(\"Parliamentary Group\")\n",
        "plt.ylabel(\"Percentage of Hateful scores\")\n",
        "plt.show()\n",
        "grouped['Hate_score'] = grouped['Hate_score'].multiply(100).round(2)\n",
        "display(grouped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "0bM8AZj483Gj",
        "outputId": "ae151d9e-000e-4ffe-96e6-b04660423974"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  parliamentary_group  Hate_score\n",
              "0                AzIV        7.28\n",
              "1                 FDI        6.34\n",
              "2                LEGA        6.76\n",
              "3                 M5S        8.64\n",
              "4                  PD        7.19"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b77afda9-3ff7-4c94-9ff1-4c1656f12585\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parliamentary_group</th>\n",
              "      <th>Hate_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AzIV</td>\n",
              "      <td>7.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FDI</td>\n",
              "      <td>6.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LEGA</td>\n",
              "      <td>6.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M5S</td>\n",
              "      <td>8.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PD</td>\n",
              "      <td>7.19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b77afda9-3ff7-4c94-9ff1-4c1656f12585')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b77afda9-3ff7-4c94-9ff1-4c1656f12585 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b77afda9-3ff7-4c94-9ff1-4c1656f12585');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by \"gender\" and calculate the percentage of \"Hateful\" scores\n",
        "grouped = df.groupby(\"gender\")[\"Hate_score\"].apply(lambda x: (x == \"Hateful\").mean()).reset_index()\n",
        "\n",
        "# Plot the percentage of \"Hateful\" scores for each gender\n",
        "plt.bar(grouped[\"gender\"], grouped[\"Hate_score\"])\n",
        "plt.xlabel(\"Gender\")\n",
        "plt.ylabel(\"Percentage of Hateful scores\")\n",
        "plt.show()\n",
        "grouped['Hate_score'] = grouped['Hate_score'].multiply(100).round(2)\n",
        "display(grouped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "N7VIukNE87Nz",
        "outputId": "8a6f750d-400b-4792-e9b3-3b1c417c4077"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  gender  Hate_score\n",
              "0      F        7.02\n",
              "1      M        6.96"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3eaaeed7-94c5-447b-b6a7-000714813d46\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>Hate_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F</td>\n",
              "      <td>7.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>6.96</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3eaaeed7-94c5-447b-b6a7-000714813d46')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3eaaeed7-94c5-447b-b6a7-000714813d46 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3eaaeed7-94c5-447b-b6a7-000714813d46');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a contingency table for the relationship between gender and Hate_score\n",
        "ct = pd.crosstab(df['gender'], df['Hate_score'], normalize='index')\n",
        "print(ct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf44TVox89m3",
        "outputId": "8a1358fa-55a0-428a-e239-36bb3eb33d62"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hate_score   Hateful  Non-Hateful\n",
            "gender                           \n",
            "F           0.070215     0.929785\n",
            "M           0.069591     0.930409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = final_df\n",
        "df['Hate_score'] = np.where(df['Hate_score'] == 'Hateful', 1, 0)\n",
        "\n",
        "model = ols('Hate_score ~ gender + parliamentary_group + gender:parliamentary_group', data=df).fit()\n",
        "\n",
        "# Conduct ANOVA test\n",
        "aov_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Print the ANOVA table\n",
        "print(aov_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nytl_ZSj2E8k",
        "outputId": "634d47cc-69a4-499d-80fc-ef0d089bd455"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  sum_sq        df          F        PR(>F)\n",
            "gender                          0.138866       1.0   2.140862  1.434232e-01\n",
            "parliamentary_group             4.540103       4.0  17.498370  2.293441e-14\n",
            "gender:parliamentary_group      1.944029       4.0   7.492638  4.968521e-06\n",
            "Residual                    10454.885470  161180.0        NaN           NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conduct Tukey's HSD test\n",
        "tukey = pairwise_tukeyhsd(df['Hate_score'], df['gender'] + '*' + df['parliamentary_group'])"
      ],
      "metadata": {
        "id": "Ddm8bw9k9CL1"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tukey_df = pd.DataFrame(data=tukey._results_table.data[1:], columns=tukey._results_table.data[0])\n",
        "tukey_df = tukey_df[tukey_df['reject'] == True]\n",
        "tukey_df = tukey_df.sort_values(by='meandiff', ascending=False)\n",
        "display(tukey_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "rlKIRi3P9E6S",
        "outputId": "63eef206-7959-4b3a-840f-3e092d6fd961"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    group1  group2  meandiff   p-adj   lower   upper  reject\n",
              "15   F*FDI   M*M5S    0.0304  0.0010  0.0185  0.0423    True\n",
              "40   M*FDI   M*M5S    0.0260  0.0010  0.0136  0.0384    True\n",
              "42  M*LEGA   M*M5S    0.0243  0.0010  0.0132  0.0355    True\n",
              "37  M*AzIV   M*M5S    0.0218  0.0010  0.0104  0.0332    True\n",
              "28   F*M5S   M*M5S    0.0211  0.0371  0.0006  0.0415    True\n",
              "11   F*FDI    F*PD    0.0152  0.0010  0.0055  0.0250    True\n",
              "33    F*PD   M*M5S    0.0152  0.0107  0.0019  0.0284    True\n",
              "12   F*FDI  M*AzIV    0.0086  0.0053  0.0015  0.0158    True\n",
              "4   F*AzIV  M*AzIV   -0.0092  0.0206 -0.0176 -0.0007    True\n",
              "32    F*PD  M*LEGA   -0.0092  0.0386 -0.0181 -0.0002    True\n",
              "8   F*AzIV    M*PD   -0.0102  0.0202 -0.0195 -0.0008    True\n",
              "31    F*PD   M*FDI   -0.0108  0.0355 -0.0212 -0.0004    True\n",
              "6   F*AzIV  M*LEGA   -0.0117  0.0010 -0.0198 -0.0036    True\n",
              "5   F*AzIV   M*FDI   -0.0134  0.0010 -0.0231 -0.0036    True\n",
              "0   F*AzIV   F*FDI   -0.0178  0.0010 -0.0269 -0.0088    True\n",
              "44   M*M5S    M*PD   -0.0228  0.0010 -0.0349 -0.0107    True"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f1a7f8c-38cd-47a7-8adf-1bbff8f2680d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group1</th>\n",
              "      <th>group2</th>\n",
              "      <th>meandiff</th>\n",
              "      <th>p-adj</th>\n",
              "      <th>lower</th>\n",
              "      <th>upper</th>\n",
              "      <th>reject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>F*FDI</td>\n",
              "      <td>M*M5S</td>\n",
              "      <td>0.0304</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0185</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>M*FDI</td>\n",
              "      <td>M*M5S</td>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>0.0384</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>M*LEGA</td>\n",
              "      <td>M*M5S</td>\n",
              "      <td>0.0243</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0132</td>\n",
              "      <td>0.0355</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>M*AzIV</td>\n",
              "      <td>M*M5S</td>\n",
              "      <td>0.0218</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.0332</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>F*M5S</td>\n",
              "      <td>M*M5S</td>\n",
              "      <td>0.0211</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.0415</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>F*FDI</td>\n",
              "      <td>F*PD</td>\n",
              "      <td>0.0152</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0055</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>F*PD</td>\n",
              "      <td>M*M5S</td>\n",
              "      <td>0.0152</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>F*FDI</td>\n",
              "      <td>M*AzIV</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>0.0053</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0158</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F*AzIV</td>\n",
              "      <td>M*AzIV</td>\n",
              "      <td>-0.0092</td>\n",
              "      <td>0.0206</td>\n",
              "      <td>-0.0176</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>F*PD</td>\n",
              "      <td>M*LEGA</td>\n",
              "      <td>-0.0092</td>\n",
              "      <td>0.0386</td>\n",
              "      <td>-0.0181</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>F*AzIV</td>\n",
              "      <td>M*PD</td>\n",
              "      <td>-0.0102</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>-0.0195</td>\n",
              "      <td>-0.0008</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>F*PD</td>\n",
              "      <td>M*FDI</td>\n",
              "      <td>-0.0108</td>\n",
              "      <td>0.0355</td>\n",
              "      <td>-0.0212</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>F*AzIV</td>\n",
              "      <td>M*LEGA</td>\n",
              "      <td>-0.0117</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>-0.0198</td>\n",
              "      <td>-0.0036</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>F*AzIV</td>\n",
              "      <td>M*FDI</td>\n",
              "      <td>-0.0134</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>-0.0231</td>\n",
              "      <td>-0.0036</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F*AzIV</td>\n",
              "      <td>F*FDI</td>\n",
              "      <td>-0.0178</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>-0.0269</td>\n",
              "      <td>-0.0088</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>M*M5S</td>\n",
              "      <td>M*PD</td>\n",
              "      <td>-0.0228</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>-0.0349</td>\n",
              "      <td>-0.0107</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f1a7f8c-38cd-47a7-8adf-1bbff8f2680d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f1a7f8c-38cd-47a7-8adf-1bbff8f2680d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f1a7f8c-38cd-47a7-8adf-1bbff8f2680d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "df = final_df\n",
        "\n",
        "# convert categorical variables to factors\n",
        "df['gender'] = df['gender'].astype('category')\n",
        "df['parliamentary_group'] = df['parliamentary_group'].astype('category')\n",
        "df['Hate_score'] = df['Hate_score'].astype('category')\n",
        "df['Sentiment'] = df['Sentiment'].astype('category')\n",
        "\n",
        "# standardize the predictors\n",
        "scaler = StandardScaler()\n",
        "df[['followers_count']] = scaler.fit_transform(df[['followers_count']])\n",
        "\n",
        "# create a multilevel model\n",
        "mlogit = sm.GLM.from_formula(\"Hate_score ~ Sentiment + followers_count + C(gender) + C(parliamentary_group)\", \n",
        "                              family=sm.families.Binomial(), data=df)\n",
        "\n",
        "# fit the model\n",
        "model_fit = mlogit.fit()\n",
        "\n",
        "# summarize the results\n",
        "print(model_fit.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofq3sllN9NbA",
        "outputId": "9e6bcec8-1782-4440-d2eb-c12965e6b062"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 Generalized Linear Model Regression Results                                  \n",
            "==============================================================================================================\n",
            "Dep. Variable:     ['Hate_score[Hateful]', 'Hate_score[Non-Hateful]']   No. Observations:               161190\n",
            "Model:                                                            GLM   Df Residuals:                   161182\n",
            "Model Family:                                                Binomial   Df Model:                            7\n",
            "Link Function:                                                  logit   Scale:                          1.0000\n",
            "Method:                                                          IRLS   Log-Likelihood:                -40692.\n",
            "Date:                                                Tue, 07 Feb 2023   Deviance:                       81383.\n",
            "Time:                                                        16:56:20   Pearson chi2:                 1.61e+05\n",
            "No. Iterations:                                                     6                                         \n",
            "Covariance Type:                                            nonrobust                                         \n",
            "==================================================================================================\n",
            "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Intercept                         -2.4766      0.026    -96.567      0.000      -2.527      -2.426\n",
            "Sentiment[T.positive]             -0.2061      0.023     -8.826      0.000      -0.252      -0.160\n",
            "C(gender)[T.M]                    -0.0263      0.024     -1.076      0.282      -0.074       0.022\n",
            "C(parliamentary_group)[T.FDI]     -0.1068      0.030     -3.559      0.000      -0.166      -0.048\n",
            "C(parliamentary_group)[T.LEGA]    -0.0933      0.027     -3.413      0.001      -0.147      -0.040\n",
            "C(parliamentary_group)[T.M5S]      0.2020      0.044      4.603      0.000       0.116       0.288\n",
            "C(parliamentary_group)[T.PD]      -0.0153      0.030     -0.514      0.607      -0.073       0.043\n",
            "followers_count                    0.0750      0.010      7.782      0.000       0.056       0.094\n",
            "==================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fLFlJplQW7GM",
        "outputId": "35e8a5bc-dbbe-4ae0-b419-a0875a3712a9"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Tweet_ID   Hate_score  followers_count gender  \\\n",
              "0       1610630350279004160      Hateful        -0.773593      M   \n",
              "1       1610630350279004160  Non-Hateful        -0.773593      M   \n",
              "2       1610630350279004160      Hateful        -0.773593      M   \n",
              "3       1610630350279004160  Non-Hateful        -0.773593      M   \n",
              "4       1610630350279004160  Non-Hateful        -0.773593      M   \n",
              "...                     ...          ...              ...    ...   \n",
              "161185  1618874638393839617  Non-Hateful        -0.796894      M   \n",
              "161186  1618874638393839617  Non-Hateful        -0.796894      M   \n",
              "161187  1618874638393839617      Hateful        -0.796894      M   \n",
              "161188  1618874638393839617  Non-Hateful        -0.796894      M   \n",
              "161189  1618874638393839617  Non-Hateful        -0.796894      M   \n",
              "\n",
              "       parliamentary_group Sentiment  \n",
              "0                       PD  negative  \n",
              "1                       PD  negative  \n",
              "2                       PD  negative  \n",
              "3                       PD  negative  \n",
              "4                       PD  negative  \n",
              "...                    ...       ...  \n",
              "161185                 FDI  positive  \n",
              "161186                 FDI  positive  \n",
              "161187                 FDI  positive  \n",
              "161188                 FDI  positive  \n",
              "161189                 FDI  positive  \n",
              "\n",
              "[161190 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20d59d66-4ba8-48c3-a5ec-7cb1015928d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>Hate_score</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>gender</th>\n",
              "      <th>parliamentary_group</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1610630350279004160</td>\n",
              "      <td>Hateful</td>\n",
              "      <td>-0.773593</td>\n",
              "      <td>M</td>\n",
              "      <td>PD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1610630350279004160</td>\n",
              "      <td>Non-Hateful</td>\n",
              "      <td>-0.773593</td>\n",
              "      <td>M</td>\n",
              "      <td>PD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1610630350279004160</td>\n",
              "      <td>Hateful</td>\n",
              "      <td>-0.773593</td>\n",
              "      <td>M</td>\n",
              "      <td>PD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1610630350279004160</td>\n",
              "      <td>Non-Hateful</td>\n",
              "      <td>-0.773593</td>\n",
              "      <td>M</td>\n",
              "      <td>PD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1610630350279004160</td>\n",
              "      <td>Non-Hateful</td>\n",
              "      <td>-0.773593</td>\n",
              "      <td>M</td>\n",
              "      <td>PD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161185</th>\n",
              "      <td>1618874638393839617</td>\n",
              "      <td>Non-Hateful</td>\n",
              "      <td>-0.796894</td>\n",
              "      <td>M</td>\n",
              "      <td>FDI</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161186</th>\n",
              "      <td>1618874638393839617</td>\n",
              "      <td>Non-Hateful</td>\n",
              "      <td>-0.796894</td>\n",
              "      <td>M</td>\n",
              "      <td>FDI</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161187</th>\n",
              "      <td>1618874638393839617</td>\n",
              "      <td>Hateful</td>\n",
              "      <td>-0.796894</td>\n",
              "      <td>M</td>\n",
              "      <td>FDI</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161188</th>\n",
              "      <td>1618874638393839617</td>\n",
              "      <td>Non-Hateful</td>\n",
              "      <td>-0.796894</td>\n",
              "      <td>M</td>\n",
              "      <td>FDI</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161189</th>\n",
              "      <td>1618874638393839617</td>\n",
              "      <td>Non-Hateful</td>\n",
              "      <td>-0.796894</td>\n",
              "      <td>M</td>\n",
              "      <td>FDI</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>161190 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20d59d66-4ba8-48c3-a5ec-7cb1015928d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20d59d66-4ba8-48c3-a5ec-7cb1015928d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20d59d66-4ba8-48c3-a5ec-7cb1015928d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    }
  ]
}